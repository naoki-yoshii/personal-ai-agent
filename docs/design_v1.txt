1. システム概要
1-1. システム名（仮）

パーソナルAIエージェント（Personal AI Agent）

1-2. 目的

Notion に蓄積された「自分の情報」を活用し、その人に最適化された回答を返すパーソナルAIを作成する。

Web情報とNotion情報を組み合わせて、一般情報＋個人文脈の両方を踏まえた回答を行う。

機能ごとにMCPサーバを分割し、小さな部品を組み合わせて拡張できる構成にする。

1-3. 想定利用環境

クライアント：

PC（ブラウザ or デスクトップクライアント）

スマホ（ブラウザ or モバイルアプリ／PWA）

バックエンド：

AIエージェント（LLM）

複数MCPサーバ（Notion/RAG、Web検索など）

2. 要求仕様
2-1. 機能要件（必須）

チャットインターフェース

PC / スマホからテキストベースで会話できる。

過去の会話履歴を踏まえて応答できる（LLM側のコンテキスト管理）。

Notion を使った RAG（Retrieval-Augmented Generation）

Notion API を利用して、自分のNotionワークスペースから情報を取得する。

Notion上の情報をベクトル化し、検索（類似度検索）ができる。

ユーザの質問に応じて、Notionから関連するページやブロックを取得し、LLMのコンテキストとして渡す。

その人に合った返答（自分のメモ・ルール・プロフィール等を踏まえた回答）を生成する。

Web情報の利用

一般的・最新情報が必要な質問に対して、Web検索MCPサーバを用いて情報を取得する。

Webから取得した情報＋Notionの情報を統合して回答できる。

AIエージェント＋MCP構成

中心となるAIエージェントがユーザの入力を解析し、

Notion RAG MCPサーバ

Web検索MCPサーバ

（将来追加のMCPサーバ）
を使い分ける。

MCPサーバは、できるだけ**単一責務（単機能）**になるよう分割する。

2-2. 機能要件（将来拡張）

位置情報MCPサーバ

ユーザの現在地（例：スマホのGPS情報）を取得する。

周辺のお店情報API（Google Maps, ぐるなび 等）を呼び出して、ランチ候補を取得する。

「現在地近くでおすすめランチ教えて」といった質問に対応。

その他の機能拡張

スケジュール管理MCP（Googleカレンダー連携など）

タスク管理MCP（Todo管理ツール連携など）

家計簿・資産管理MCP　など

2-3. 非機能要件

コスト最適化

個人利用を想定し、LLMのトークン使用量を抑える設計。

不要なMCP呼び出しを行わない（必要なときだけNotion/Webを叩く）。

Notionデータは定期同期＆ローカルキャッシュ（ベクトルDB）を利用し、毎回Notion APIを叩かないようにする。

保守性

MCPサーバを機能ごとに分割し、各サーバは小さな責務に限定する。

新機能追加は「新しいMCPサーバを1つ追加」する形で行える。

MCPサーバのコードはリポジトリ分割またはディレクトリ単位で分離しやすくする。

拡張性

AIエージェント側は、「どのMCPを使うか」を柔軟に選択できるように設計する。

MCPサーバの追加・削除に対応可能な構成。

セキュリティ・プライバシ

Notion APIトークンや各種APIキーは環境変数で管理。

個人情報を含むログは外部に出さない（必要に応じてローカル保存 or 匿名化）。

3. 全体アーキテクチャ
3-1. 論理構成図（テキスト表現）
[ユーザ（PC / スマホ）]
        |
        v
[チャットUI（Webアプリ or クライアント）]
        |
        v
[AIエージェント（LLM）]
   |           |
   |           +------------------------------+
   v                                          v
[MCP: Notion RAGサーバ]                 [MCP: Web検索サーバ]
   |                                          |
[Notion API]                              [Web検索API 等]

※将来：
[AIエージェント]
    |
    +--> [MCP: 位置情報サーバ] -> [位置情報API（ブラウザ/スマホ）]
    |
    +--> [MCP: ランチ検索サーバ] -> [飲食店検索API]

3-2. 物理構成（想定）

クライアント：

Webブラウザ（PC／スマホ共通）

サーバ：

AIエージェント：LLM提供サービス上で動作（GPT / Claude など）

MCPサーバ：

1台のVPS or ローカルPC上で複数MCPをDockerコンテナ or プロセスとして動かす想定

データストア：

Notion：ユーザ情報の一次保存

ベクトルDB：Notionデータの埋め込み・検索用（ローカル or クラウド）

4. コンポーネント設計
4-1. AIエージェント

役割

ユーザの自然文から「何をしたいか」を解釈し、適切なMCPサーバを組み合わせて呼び出す。

MCPから返ってきた情報を統合し、自然な文章で回答を生成する。

主な処理フロー（例：標準質問）

ユーザ入力を受け取る。

入力文から、以下を判断する（LLMプロンプトで実現）：

個人情報ベースの回答が必要か？（→ Notion RAG）

一般的 or 最新情報が必要か？（→ Web検索）

両方必要か？

必要なMCPサーバへツールコールを実行。

MCPからのレスポンスを集約し、最終回答を生成。

チャットUIに返却。

4-2. MCP: Notion RAGサーバ

責務

Notion APIからデータを取得し、ローカルのベクトルDBに保存・検索を行う。

AIエージェントからの「質問」に対して、関連度の高いNotionコンテンツを返す。

提供する主な機能（エンドポイント例）

sync_notion_data()

Notion APIを叩いて、対象データベース・ページを取得し、ローカルDBに同期する。

search_knowledge(query: string) -> [contexts...]

クエリ文をベクトル化し、ベクトルDBから類似ドキュメントを取得して返す。

get_raw_page(page_id: string)（必要なら）

Notionのページ本文をそのまま返す。

RAGの流れ（内部）

定期的に、または手動トリガーで sync_notion_data を実行。

取得したテキストを分割（チャンク化）し、埋め込みベクトルを生成。

ベクトルDBに (embedding, text, meta) を保存。

search_knowledge呼び出し時には、

クエリを埋め込みベクトル化

類似度検索で上位N件を取得

LLMに渡しやすい形式のテキストとして返す。

4-3. MCP: Web検索サーバ

責務

一般的な情報や最新情報をWebから取得する。

AIエージェントからのクエリを受け取り、検索結果要約または代表的なURL＋抜粋を返す。

提供する主な機能

web_search(query: string) -> [results...]

外部の検索APIを呼び出し、タイトル・URL・スニペット等を返す。

get_page_summary(url: string) -> string

指定URLの内容を取得し、要約して返す（必要に応じて実装）。

4-4. 将来追加 MCPサーバ（例）
(1) MCP: 位置情報サーバ

責務

デバイスから現在地情報（緯度・経度）を取得し、AIエージェントに渡す。

提供機能

get_current_location() -> {lat, lng}

(2) MCP: ランチ検索サーバ

責務

位置情報を受け取り、周辺の飲食店情報を検索する。

提供機能

search_lunch_spots(lat, lng, preferences) -> [restaurants...]

5. データ設計（概要）
5-1. Notionデータ → ベクトルDB構造（例）

documents テーブル（またはコレクション）

id : 内部ID

notion_page_id: NotionのページID

chunk_index: ページ内チャンク番号

text: チャンクされたテキスト本文

embedding: ベクトル

tags: 任意のタグ（カテゴリ、用途など）

updated_at: 最終更新日時

6. 開発・運用方針
6-1. リポジトリ構成案

personal-ai-agent/（メイン）

agent/ … AIエージェントの設定・プロンプトなど

mcp-notion-rag/ … Notion RAG MCPサーバ

mcp-web-search/ … Web検索 MCPサーバ

mcp-location/（将来）

mcp-lunch/（将来）

docs/ … 設計書、仕様書

README.md

※ GitHubアカウント：naoki-yoshii リポジトリとして作成予定。

6-2. コスト管理

LLMのモデルは、まずは安価なモデルを基本とし、必要に応じて高性能モデルに切り替える方針。

RAGでコンテキストを絞り込むことで、投入トークン数を減らす。

Web検索・Notion同期は必要なタイミングだけ実行し、無駄なAPIコールを避ける。

7. ユースケース例
ユースケース1：自分の学習ノートを踏まえた質問

ユーザ：「昨日Notionに書いたPythonのメモを元にfor文の書き方教えて」

AIエージェント：

Notion RAG MCPに search_knowledge("Python for文") を投げる

関連ノートを取得

ノート内容＋一般的なPython知識を元に回答

ユースケース2：最新情報＋自分の方針を踏まえた相談

ユーザ：「今の株式市場の状況を踏まえて、前にNotionに書いた投資ルールに沿うアドバイスして」

AIエージェント：

Web検索 MCPで市場の最新情報を取得

Notion RAG MCPで「自分の投資ルール」を検索

両方を踏まえて回答（※実装時は投資アドバイスの注意文も追加）

ユースケース3：周辺ランチ検索（将来）

ユーザ：「今いる場所の近くで、静かに作業できるカフェ教えて」

AIエージェント：

位置情報MCPで現在地取得

ランチ（店舗）検索MCPで条件（カフェ・静かな・作業向け）を使って検索

候補を一覧で返す

8. 今回のタスク用チェックリスト

要求仕様（機能・非機能）の整理

全体アーキテクチャの記述

MCPサーバごとの役割・機能の整理

RAG（Notion連携）の流れの整理

将来拡張（位置情報・ランチ検索）の設計方針の記述